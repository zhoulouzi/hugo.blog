

  
    
  


  




  


  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.47 with theme Tranquilpeak 0.4.3-BETA">
    <title>kubernetes install offline</title>
    <meta name="author" content="zhoulouzi">
    <meta name="keywords" content=", zhoulouzi">

    <link rel="icon" href="https://blog.zhoulouzi.com/favicon.png">
    

    
    <meta name="description" content="kubernetes install offline step by step  概述: 此文档用于在ubuntu16.04上独立安装kubernetes节点 api-server与kubelet、kube-proxy之间通过tls认证交互 control-manager和scheduler通过api-server在本地暴露的127.0.0.1:8080交互
备注： 未实现HA模式 ，实现HA模式，官方的文档https://kubernetes.io/docs/admin/high-availability/里指明：需要etcd实现集群模式，apiserver是无状态的，在master节点上正常启动，利用云上的lb做负载均衡，感觉dns也行，注意证书问题就可以。，kube-controller-manager，kube-scheduler需要保证同时只有一个实例在work启动加上--leader-elect启动参数。
 etcd组件说明： port: 127.0.0.1:2379: listen-client 127.0.0.1:2380: initial-cluster  kubelet组件说明： port: 4194: cadvisor-port #cadvisor作为kubernetes一个组件集成在kubelet里 127.0.0.1:10248: localhost healthz endpoint # 10250: Kubelet to server on listen for HTTP and respond to a simple API (underspec’d currently) to submit a new manifest. 10255: The read-only port for the Kubelet to serve on with no authentication/authorization # 只读暴露kubelet里的指标 http://192.168.199.142:10255/stats/summary  kube-proxy组件： port： 127.">
    <meta property="og:description" content="kubernetes install offline step by step  概述: 此文档用于在ubuntu16.04上独立安装kubernetes节点 api-server与kubelet、kube-proxy之间通过tls认证交互 control-manager和scheduler通过api-server在本地暴露的127.0.0.1:8080交互
备注： 未实现HA模式 ，实现HA模式，官方的文档https://kubernetes.io/docs/admin/high-availability/里指明：需要etcd实现集群模式，apiserver是无状态的，在master节点上正常启动，利用云上的lb做负载均衡，感觉dns也行，注意证书问题就可以。，kube-controller-manager，kube-scheduler需要保证同时只有一个实例在work启动加上--leader-elect启动参数。
 etcd组件说明： port: 127.0.0.1:2379: listen-client 127.0.0.1:2380: initial-cluster  kubelet组件说明： port: 4194: cadvisor-port #cadvisor作为kubernetes一个组件集成在kubelet里 127.0.0.1:10248: localhost healthz endpoint # 10250: Kubelet to server on listen for HTTP and respond to a simple API (underspec’d currently) to submit a new manifest. 10255: The read-only port for the Kubelet to serve on with no authentication/authorization # 只读暴露kubelet里的指标 http://192.168.199.142:10255/stats/summary  kube-proxy组件： port： 127.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="kubernetes install offline">
    <meta property="og:url" content="/2017/11/kubernetes/">
    <meta property="og:site_name" content="zhoulouzi&#39;s Blog">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="zhoulouzi&#39;s Blog">
    <meta name="twitter:description" content="kubernetes install offline step by step  概述: 此文档用于在ubuntu16.04上独立安装kubernetes节点 api-server与kubelet、kube-proxy之间通过tls认证交互 control-manager和scheduler通过api-server在本地暴露的127.0.0.1:8080交互
备注： 未实现HA模式 ，实现HA模式，官方的文档https://kubernetes.io/docs/admin/high-availability/里指明：需要etcd实现集群模式，apiserver是无状态的，在master节点上正常启动，利用云上的lb做负载均衡，感觉dns也行，注意证书问题就可以。，kube-controller-manager，kube-scheduler需要保证同时只有一个实例在work启动加上--leader-elect启动参数。
 etcd组件说明： port: 127.0.0.1:2379: listen-client 127.0.0.1:2380: initial-cluster  kubelet组件说明： port: 4194: cadvisor-port #cadvisor作为kubernetes一个组件集成在kubelet里 127.0.0.1:10248: localhost healthz endpoint # 10250: Kubelet to server on listen for HTTP and respond to a simple API (underspec’d currently) to submit a new manifest. 10255: The read-only port for the Kubelet to serve on with no authentication/authorization # 只读暴露kubelet里的指标 http://192.168.199.142:10255/stats/summary  kube-proxy组件： port： 127.">
    
      <meta name="twitter:creator" content="@zhoulouzi">
    
    

    
    

    
      <meta property="og:image" content="//www.gravatar.com/avatar/f56039ed04a4e2f1901c1b07449f6e5a?s=640">
    

    
      <meta property="og:image" content="https://res.cloudinary.com/ddvxfzzbe/image/upload/v1513355321/Real_gaggav.png">
    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://blog.zhoulouzi.com/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-110602463-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="5">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://blog.zhoulouzi.com/">zhoulouzi&#39;s Blog</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://blog.zhoulouzi.com/#about">
    
    
    
      
        <img class="header-picture" src="//www.gravatar.com/avatar/f56039ed04a4e2f1901c1b07449f6e5a?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="5">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://blog.zhoulouzi.com/#about">
          <img class="sidebar-profile-picture" src="//www.gravatar.com/avatar/f56039ed04a4e2f1901c1b07449f6e5a?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">zhoulouzi</h4>
        
          <h5 class="sidebar-profile-bio">KEEP FOCUS AND CARRY ON</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://blog.zhoulouzi.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://blog.zhoulouzi.com/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://blog.zhoulouzi.com/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://blog.zhoulouzi.com/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/zhoulouzi" target="_blank" rel="noopener">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://twitter.com/zhoulouzi" target="_blank" rel="noopener">
    
      <i class="sidebar-button-icon fa fa-lg fa-twitter"></i>
      
      <span class="sidebar-button-desc">twitter</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="5"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-center">
  
    <h1 class="post-title" itemprop="headline">
      kubernetes install offline
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2017-11-07T21:48:15&#43;08:00">
        
  November 7, 2017

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="https://blog.zhoulouzi.com/categories/docker">docker</a>, 
    
      <a class="category-link" href="https://blog.zhoulouzi.com/categories/kubernetes">kubernetes</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              

<h1 id="kubernetes-install-offline-step-by-step">kubernetes install offline step by step</h1>

<blockquote>
<p>概述:
此文档用于在ubuntu16.04上独立安装kubernetes节点
api-server与kubelet、kube-proxy之间通过tls认证交互
control-manager和scheduler通过api-server在本地暴露的127.0.0.1:8080交互</p>

<p>备注：
未实现HA模式  ，实现HA模式，官方的文档<a href="https://kubernetes.io/docs/admin/high-availability/里指明：需要etcd实现集群模式，apiserver是无状态的，在master节点上正常启动，利用云上的lb做负载均衡，感觉dns也行，注意证书问题就可以。，kube-controller-manager，kube-scheduler需要保证同时只有一个实例在work启动加上--leader-elect启动参数。">https://kubernetes.io/docs/admin/high-availability/里指明：需要etcd实现集群模式，apiserver是无状态的，在master节点上正常启动，利用云上的lb做负载均衡，感觉dns也行，注意证书问题就可以。，kube-controller-manager，kube-scheduler需要保证同时只有一个实例在work启动加上--leader-elect启动参数。</a></p>
</blockquote>

<h3 id="etcd组件说明">etcd组件说明：</h3>

<pre><code>port:
    127.0.0.1:2379: listen-client
    127.0.0.1:2380: initial-cluster
</code></pre>

<h3 id="kubelet组件说明">kubelet组件说明：</h3>

<pre><code>port:
    4194:       cadvisor-port                      #cadvisor作为kubernetes一个组件集成在kubelet里
    127.0.0.1:10248:    localhost healthz endpoint #
    10250:     Kubelet to server on  listen for HTTP and respond to a simple API (underspec’d currently) to submit a new manifest.
    10255:    The read-only port for the Kubelet to serve on with no authentication/authorization
        # 只读暴露kubelet里的指标 http://192.168.199.142:10255/stats/summary
</code></pre>

<h3 id="kube-proxy组件">kube-proxy组件：</h3>

<pre><code>port：
    127.0.0.1:10249:   metrics server to serve on   # metrics server 并未安装待探索
    10256:   health check server port
    代理的其他服务端口
</code></pre>

<h3 id="apiserver-组件说明">apiserver 组件说明：</h3>

<pre><code>port:
    127.0.0.1:8080:     insecure-port
    6443:           secure-port
</code></pre>

<h5 id="api-认证策略-authentication-strategies">API 认证策略（Authentication strategies）：</h5>

<p>X509 Client Certs、Service Account Tokens
        # <a href="https://kubernetes.io/docs/admin/authentication/">https://kubernetes.io/docs/admin/authentication/</a></p>

<h5 id="api-授权模式-authorization-mozules">API 授权模式（Authorization Mozules）:</h5>

<p>Node、RBAC
        # <a href="https://kubernetes.io/docs/admin/authorization/">https://kubernetes.io/docs/admin/authorization/</a></p>

<h3 id="kube-controller-manager组件说明">kube-controller-manager组件说明：</h3>

<pre><code>port:
    10252:      the controller-manager's http service runs on
</code></pre>

<h3 id="kube-scheduler组件说明">kube-scheduler组件说明：</h3>

<pre><code>port:
    10251:          the scheduler's http service runs on
</code></pre>

<h3 id="kube-dns组件说明">kube-dns组件说明：</h3>

<pre><code>k8s-dns-sidecar：        # daemon that exports metrics and performs healthcheck on DNS systems.
    10054：      metrics
    dnsmasq:            # 集群内部默认的dns服务
    53  tcp/udp
kube-dns:           # 与apiserver交互
    10053  tcp/udp      #监听来自dnsmasq的 forward请求
备注：
如果reslov.conf 里面是127.0.1.1，本地启动的dnsmasq，在容器里会出现解析外网有问题。
</code></pre>

<p><a href="https://github.com/kubernetes/kubernetes/issues/31337">https://github.com/kubernetes/kubernetes/issues/31337</a>
如果你是这种情况 给你的kubelet添加启动参数 &ndash;resolv-conf自定义你的resolv.conf文件或者  DISABLE DNSMASQ的方式完成。
<a href="https://docs.docker.com/engine/installation/linux/linux-postinstall/#specify-dns-servers-for-docker">https://docs.docker.com/engine/installation/linux/linux-postinstall/#specify-dns-servers-for-docker</a> 这个文章 可以详细看看</p>

<h2 id="组件清单">组件清单:</h2>

<blockquote>
<p>组件介绍官方文档:<a href="https://kubernetes.io/docs/concepts/overview/components/">https://kubernetes.io/docs/concepts/overview/components/</a></p>
</blockquote>

<p>### kubernetes核心组件:
      二进制:                      版本
    kubectl :kubernetes 客户端工具
    kubelet                     Kubernetes v1.8.3
    kube-proxy                  Kubernetes v1.8.3
      容器方式:                     镜像
    etcd                        gcr.io/google_containers/etcd-amd64:3.0.17
    kube-apiserver                  gcr.io/google_containers/kube-apiserver-amd64:v1.8.3
    kube-controller-manager             gcr.io/google_containers/kube-controller-manager-amd64:v1.8.3
    kube-scheduler                  gcr.io/google_containers/kube-scheduler- amd64:v1.8.3
    kubernetes-addons: addons 手动部署，自动的好像要加label没搞明白
       容器方式:                        镜像
    kube-dns                    gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.7
                            gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.7
                            gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.7
    kube-dns-autoscaler             gcr.io/google_containers/cluster-proportional-autoscaler-amd64:1.0.0
    kube-dashboard                  gcr.io/google_containers/kubernetes-dashboard-init-amd64:v1.0.1
                            gcr.io/google_containers/kubernetes-dashboard-amd64:v1.7.1
    heapster                    gcr.io/google_containers/heapster-amd64:v1.4.0
    calico                      quay.io/calico/node:v2.6.2
                            quay.io/calico/kube-controllers:v1.0.0
                            quay.io/calico/cni:v1.11.0
    pause                       gcr.io/google_containers/pause-amd64:3.0</p>

<p>打包结构如下：</p>

<pre><code>kubernetes_install:
    /binary                     # 包含所需组件的二进制文件和docker镜像
        /二进制\镜像如上列表
        /save.sh                #用于本地打包镜像
    /docker_install
        /docker-ce_17.03.2~ce-0~ubuntu-xenial_amd64.deb
        /install                    #docker 安装脚本
    /conf   配置模板
        /mainfests                  #kubelet manifests yaml
            /etcd.yaml
            /kubernetes-apiserver.yaml
            /kubernetes-controller-manager.yaml
            /kubernetes-scheduler.yaml
/kube-addon-manager.yaml            s
        /addons                 #kubernetes addons yaml
            /kubernetes-dashboard.yaml
/dashboard-admin.yaml       #dashboard的权限
/kubernetes-dns.yml
/heapster.yaml
/heapster-rbac.yaml
/dns-horizontal-autoscaler.yaml
/calico.yaml
/calico-rbac.yaml
    /certs                      #存放生成的证书
        /templates              #cfss csr模板s
/apiserver-csr.conf.template
/ca-config.json         #cfssl ca的config文件
/ca-csr.json                #cfssl ca证书的csr文件
/kube-admin-csr.json.template
/kubelet-csr.json.template
/kube-proxy-csr.json
    /scripts
        /kubernetes_install.sh      #节点执行的脚本
        /node_var_template          #节点变量模板
    /INSTALL                    #安装主脚本
    /cfssl_to_kubernetes.sh         #证书生成脚本，被INSTALL调用
    /cluster_var                    #定义集群参数
    /README.md                  #说明
</code></pre>

<h2 id="安装步骤">安装步骤：</h2>

<h3 id="1-准备环境">1.准备环境:</h3>

<h4 id="1-1-安装docker">1.1 安装docker:</h4>

<pre><code>建议docker版本:17.03.2-ce
环境确认：
net.ipv4.ip_forward = 1
iptables -P FORWARD ACCEPT          大小写敏感
docker  官方关于 ufw ：forward 表 默认drop的说明：
https://docs.docker.com/engine/installation/linux/linux-postinstall/#allow-access-to-the-remote-api-through-a-firewall
kubernetes  kube-proxy 关于这个问题的fix：
https://github.com/kubernetes/kubernetes/pull/52569

如果docker 安装有问题请参阅:https://docs.docker.com/engine/installation/linux/linux-postinstall/
</code></pre>

<h4 id="1-2-环境准备">1.2 环境准备:</h4>

<pre><code>关闭swap: swapoff -a
安装conntrack包: apt install conntrack
# kube-proxy的依赖，没有kube-proxy可能起不来
</code></pre>

<h3 id="2-处理iptables">2.处理iptables:</h3>

<pre><code>删除docker创建的网桥:
systemctl stop docker
iptables -t nat -F
ip link set docker0 down
ip link delete docker0

使用calico 此处不需要删除docker建立的bridge。
新建 cbr0:
ip link add name cbr0 type bridge
ip link set dev cbr0 mtu 1460
ip addr add 10.0.0.1/16 dev cbr0                    #此处IP为 pod range ip 的第一位
ip link set dev cbr0 up
iptables -t nat -A POSTROUTING ! -d 192.168.199.0/24 -m addrtype ! --dst-type LOCAL -j MASQUERADE
</code></pre>

<h3 id="3-处理docker启动参数">3.处理docker启动参数:</h3>

<pre><code>cp  kubernetes_install/conf/systemd/docker.service  /lib/systemd/system/docker.service
具体docker参数: --bridge=cbr0 --ip-masq=false --iptables=false  --bridge=node --exec-root=/var/run/docker
LimitNOFILE=1048576
脚本处理时，dockerd的参数全部放置在了daemon.json
完整的 dockerd 配置手册 https://docs.docker.com/engine/reference/commandline/dockerd/
</code></pre>

<h3 id="4-处理kubelet启动参数">4.处理kubelet启动参数</h3>

<pre><code>    cp  kubernetes_install/conf/systemd/kubelet.service  /lib/systemd/system/kubelet.service
具体kubelet参数:   --allow-privileged --kubeconfig=/var/lib/kubelet/kubeconfig --pod-manifest-path=/etc/kubernetes/manifests --cluster-dns=10.96.0.10  --cluster-domain=cluster.local  --register-node --hostname-override=192.168.199.142 --node-ip 192.168.199.142  --network-plugin=cni
</code></pre>

<h3 id="5-处理kube-proxy启动参数">5.处理kube-proxy启动参数</h3>

<pre><code>cp  kubernetes_install/conf/systemd/kube-proxy.service  /lib/systemd/system/kube-proxy.service
具体kube-proxy参数:  --proxy-mode=iptables --hostname-override=192.168.199.142 --master=https://192.168.199.142:6443 --kubeconfig=/var/lib/kube-proxy/kubeconfig --proxy-port-range=1-65535 --cluster-cidr=10.0.0.0/16
脚本内 --proxy-port-range=1-65535 没有打开 默认3000以上端口，看后期需求

修改参数3\4\5完毕之后执行systemctl daemon-reload
重启3\4\5中的服务
</code></pre>

<h3 id="6-复制kubernetes-apiserver-yaml到宿主机-etc-kubernetes-manifests">6.复制kubernetes-apiserver.yaml到宿主机/etc/kubernetes/manifests</h3>

<pre><code>cp  kubernetes_install/conf/manifests/kubernetes-apiserver.yaml /etc/kubernetes/manifests/kubernetes-apiserver.yaml
apiserver的启动参数:
kube-apiserver
    - --allow-privileged=true
    - --address=192.168.199.142
    - --service-cluster-ip-range=10.96.0.0/12
    - --etcd-servers=http://127.0.0.1:2379
    - --client-ca-file=/srv/kubernetes/ca.crt
    - --tls-cert-file=/srv/kubernetes/apiserver.crt
    - --tls-private-key-file=/srv/kubernetes/apiserver.key
    - --admission-control=Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota
    - --allow-privileged=true
    - --insecure-bind-address=127.0.0.1
    - --advertise-address=192.168.199.142
    - --authorization-mode=Node,RBAC
    - --service-node-port-range=0-65535
</code></pre>

<h3 id="7-复制yaml配置文件">7.复制yaml配置文件</h3>

<pre><code>cp  kubernetes_install/conf/manifests/kubernetes-controller-manager.yaml /etc/kubernetes/manifests/kubernetes-controller-manager.yaml
cp  kubernetes_install/conf/manifests/kubernetes-scheduler.yaml /etc/kubernetes/manifests/kubernetes-scheduler.yaml
cp kubernetes_install/conf/addons/* /etc/kubernetes/addons/
</code></pre>

<h3 id="8-证书生成">8.证书生成:</h3>

<p>脚本使用的cfssl，简单无脑</p>

<h4 id="8-1-ca证书生成">8.1 CA证书生成：</h4>

<pre><code>openssl genrsa -out ca.key 2048
openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=${MASTER_IP}&quot; -days 10000 -out ca.crt

# Distributing Self-Signed CA Certificate
sudo cp ca.crt /usr/local/share/ca-certificates/kubernetes.crt
sudo update-ca-certificates
</code></pre>

<h4 id="8-2-apiserver证书生成">8.2 apiserver证书生成：</h4>

<pre><code>openssl genrsa -out apiserver.key 2048
修改 kubernetes_install/cert/openssl/apiserver.csr.conf 文件分别将 &lt;MASTER_IP&gt;   &lt;MASTER_CLUSTER_IP&gt;替换
openssl req -new -key apiserver.key -out apiserver.csr -config apiserver.csr.conf
openssl x509 -req -in apiserver.csr -CA ca.crt -CAkey ca.key \
 -CAcreateserial -out apiserver.crt -days 10000 \
-extensions v3_ext -extfile apiserver.csr.conf
</code></pre>

<h4 id="8-3-kubelet证书生成">8.3 kubelet证书生成：</h4>

<pre><code>openssl genrsa -out kubelet.key 2048
openssl req -new -key kubelet.key -out kubelet-csr.pem -subj  &quot;/CN=system:node:${nodeip}/O=system:nodes&quot;
        # https://kubernetes.io/docs/admin/authorization/rbac/#default-roles-and-role-bindings
openssl x509 -req -in kubelet-csr.pem -CA ca.crt -CAkey ca.key -CAcreateserial -out kubelet.crt -days 10000
</code></pre>

<h4 id="8-4-kube-proxy证书生成">8.4 kube-proxy证书生成：</h4>

<pre><code>openssl genrsa -out kube-proxy.key 2048
openssl req -new -key kubelet-proxy.key -out kube-proxy-csr.pem -subj  &quot;/CN=system:kube-proxy&quot;
        # https://kubernetes.io/docs/admin/authorization/rbac/#default-roles-and-role-bindings
openssl x509 -req -in kube-proxy-csr.pem -CA ca.crt -CAkey ca.key -CAcreateserial -out kube-proxy.crt -days 10000
</code></pre>

<h4 id="8-4-kube-admin证书生成">8.4 kube-admin证书生成：</h4>

<pre><code>openssl genrsa -out kube-admin.key 2048
openssl req -new -key kube-admin.key -out kube-admin-csr.pem -subj  &quot;/CN=kube-admin/O=system:masters&quot;
        # https://kubernetes.io/docs/admin/authorization/rbac/#default-roles-and-role-bindings
openssl x509 -req -in kube-admin-csr.pem -CA ca.crt -CAkey ca.key -CAcreateserial -out kube-admin.crt -days 10000

将所有生成的crt key 复制到 /srv/kubernetes；should separate differnt crt/key
</code></pre>

<h3 id="9-kubeconfig文件生成">9 kubeconfig文件生成：</h3>

<pre><code>利用kubectl生成: should point generate config file
</code></pre>

<h4 id="9-1-kubelet-kubeconfig-文件生成">9.1 kubelet-kubeconfig 文件生成：</h4>

<pre><code>kubectl config set-cluster k8s --certificate-authority=/srv/kubernetes/ca.crt --embed-certs=true --server=https://192.168.199.142:6443
kubectl config set-credentials kubelet --client-certificate=/srv/kubernetes/kubelet.crt --client-key=/srv/kubernetes/kubelet.key --embed-certs=true
kubectl config set-context k8s_kubelet --cluster=k8s --user=kubelet
kubectl config use-context k8s_kubelet
mv /root/.kube/config  /var/lib/kubelet/kubeconfig
</code></pre>

<h4 id="9-2-kube-proxy-kubeconfig-文件生成">9.2 kube-proxy-kubeconfig 文件生成：</h4>

<pre><code>kubectl config set-cluster k8s --certificate-authority=/srv/kubernetes/ca.crt --embed-certs=true --server=https://192.168.199.142:6443
kubectl config set-credentials system:kube-proxy --client-certificate=/srv/kubernetes/kube-proxy.crt --client-key=/srv/kubernetes/kube-proxy.key --embed-certs=true
kubectl config set-context k8s_kube-proxy --cluster=k8s --user=system:kube-proxy
kubectl config use-context k8s_kube-proxy
mv /root/.kube/config  /var/lib/kube-proxy/kubeconfig
</code></pre>

<h4 id="9-3-admin-kubeconfig-文件生成">9.3 admin-kubeconfig 文件生成：</h4>

<pre><code>kubectl config set-cluster k8s --certificate-authority=/srv/kubernetes/ca.crt --embed-certs=true --server=https://192.168.199.142:6443
kubectl config set-credentials kube-admin --client-certificate=/srv/kubernetes/ kube-admin.crt --client-key=/srv/kubernetes/ kube-admin.key --embed-certs=true
kubectl config set-context k8s_kube-admin --cluster=k8s --user=kube-admin
kubectl config use-context kube-admin
备份你的admin-kubeconfig。
</code></pre>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="https://blog.zhoulouzi.com/tags/kubernetes/">kubernetes</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://blog.zhoulouzi.com/2017/11/raft/" data-tooltip="Raft 初识">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://blog.zhoulouzi.com/2018/01/kubernetes/" data-tooltip="kubectl explain">
              
                  <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://blog.zhoulouzi.com/2017/11/kubernetes/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2018 zhoulouzi. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://blog.zhoulouzi.com/2017/11/raft/" data-tooltip="Raft 初识">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://blog.zhoulouzi.com/2018/01/kubernetes/" data-tooltip="kubectl explain">
              
                  <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://blog.zhoulouzi.com/2017/11/kubernetes/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="5">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fblog.zhoulouzi.com%2F2017%2F11%2Fkubernetes%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="//www.gravatar.com/avatar/f56039ed04a4e2f1901c1b07449f6e5a?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">zhoulouzi</h4>
    
      <div id="about-card-bio">KEEP FOCUS AND CARRY ON</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Dev ops
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        China Beijing
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://blog.zhoulouzi.com/2018/08/kubernetes/">
                <h3 class="media-heading">calico-flannel-weave</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Aug 8, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">calico: calico提供了多种部署方式，ipip，node-to-node BGP mesh，global/node specific 需要根据你的依赖网络环境来决定如何部署。 ipip: calico 会在每个node之间配置一个ip tunnel来转发package node-to-node BGP mesh: 每个节点利用bird建立bgp peer关系，节点通过路由表来转发packag(官方推荐是小于50个节点)
要看的几篇文章： https://docs.projectcalico.org/v3.1/reference/architecture/ https://docs.projectcalico.org/v3.1/reference/architecture/components https://docs.projectcalico.org/v3.1/reference/architecture/data-path
https://docs.projectcalico.org/v3.1/reference/private-cloud/l2-interconnect-fabric https://docs.projectcalico.org/v3.1/reference/private-cloud/l3-interconnect-fabric
简单测试数据 [ 6] 0.0-10.0 sec 1.07 GBytes 920 Mbits/sec [ 5] 0.0-10.0 sec 1.09 GBytes 937 Mbits/sec
flannel vxlan backend: work in kernel space
udp backend: work in userspace docker0 &mdash; flanel0(tun) &mdash; flanneld https://blog.laputa.io/kubernetes-flannel-networking-6a1cb1f8ec7c https://docs.openshift.com/container-platform/3.10/architecture/networking/network_plugins.html vxlan https://www.slideshare.net/enakai/how-vxlan-works-on-linux https://events.static.linuxfound.org/sites/events/files/slides/2013-linuxcon.pdf
WEAVE NET FastDataPath: kernel space sleeve: userspace
特点 Virtual Ethernet Switch Weave Net creates a virtual network that connects Docker containers deployed across multiple hosts.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://blog.zhoulouzi.com/2018/03/kubernetes-local/">
                <h3 class="media-heading">kubernetes-local-perisistent-storage</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Kubernetes-local-perisistent-storage 最近苦于公司没有上ceph、gluster、nfs这些volume provider，用了很久的hostpath+nodeselector，但是二者组合的方式对于部署statefulset的应用来说，很不方便，kubecon上有关于local-perisistent-storage这块的介绍吸引了我们来试试这个local volume的威力。 首先，我们来看一下文档 1、local volume的介绍(https://kubernetes.io/docs/concepts/storage/volumes/#local) 2、github：(https://github.com/kubernetes-incubator/external-storage/tree/master/local-volume）
仔细阅读了这两篇文章之后，我们来做个实验。 环境： kubernets 1.9.3
step1： api-server, controller-manager, scheduler, and all kubelets 开启 feature-gates的功能：
 --feature-gates=PersistentLocalVolumes=true,VolumeScheduling=true,MountPropagation=true  step2: Creating a StorageClass:
 $ cat local-storage.yaml # Only create this for K8s 1.9+ apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: local-storage provisioner: kubernetes.io/no-provisioner volumeBindingMode: WaitForFirstConsumer
 step3: Manually create local persistent volume
 #文档中提供了一个 local volume static provisioner ，大概的功能就是 自动将你定义的path里的子文件夹 创建成 persistent volume #这里没有使用这种方式，而是选择了手动创建。 这里一定要关注一下 pv的 accessModes persistentVolumeReclaimPolicy 这两个参数，理解他们的意思。</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://blog.zhoulouzi.com/2018/01/kubernetes/">
                <h3 class="media-heading">kubectl explain</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jan 1, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">kubectl explain 之前很头疼kubernets的yaml文件怎么写，后天发现其实如果你装好了了kubectl你就随时随地的可以找到配置文件怎么写，kubectl explain 搭配 kubernetes官网API文档，yaml配置层级很清晰。
# kubectl explain -h kubectl explain secrets kubectl explain secrets --recursive DESCRIPTION: Secret holds secret data of a certain type. The total bytes of the values in the Data field must be less than MaxSecretSize bytes. FIELDS: apiVersion &lt;string&gt; data &lt;map[string]string&gt; kind &lt;string&gt; metadata &lt;Object&gt; annotations &lt;map[string]string&gt; clusterName &lt;string&gt; creationTimestamp &lt;string&gt; deletionGracePeriodSeconds &lt;integer&gt; deletionTimestamp &lt;string&gt; finalizers &lt;[]string&gt; generateName &lt;string&gt; generation &lt;integer&gt; initializers &lt;Object&gt; pending &lt;[]Object&gt; name &lt;string&gt; result &lt;Object&gt; apiVersion &lt;string&gt; code &lt;integer&gt; details &lt;Object&gt; causes &lt;[]Object&gt; field &lt;string&gt; message &lt;string&gt; reason &lt;string&gt; group &lt;string&gt; kind &lt;string&gt; name &lt;string&gt; retryAfterSeconds &lt;integer&gt; uid &lt;string&gt; kind &lt;string&gt; message &lt;string&gt; metadata &lt;Object&gt; continue &lt;string&gt; resourceVersion &lt;string&gt; selfLink &lt;string&gt; reason &lt;string&gt; status &lt;string&gt; labels &lt;map[string]string&gt; name &lt;string&gt; namespace &lt;string&gt; ownerReferences &lt;[]Object&gt; apiVersion &lt;string&gt; blockOwnerDeletion &lt;boolean&gt; controller &lt;boolean&gt; kind &lt;string&gt; name &lt;string&gt; uid &lt;string&gt; resourceVersion &lt;string&gt; selfLink &lt;string&gt; uid &lt;string&gt; stringData &lt;map[string]string&gt; type &lt;string&gt; 试着在终端敲下这几个命令。（爸爸再也不用担心我写配置了）  额外分享一个工具，看看是什么吧？ Registry creds &lt;-&gt; config.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://blog.zhoulouzi.com/2017/11/kubernetes/">
                <h3 class="media-heading">kubernetes install offline</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">kubernetes install offline step by step  概述: 此文档用于在ubuntu16.04上独立安装kubernetes节点 api-server与kubelet、kube-proxy之间通过tls认证交互 control-manager和scheduler通过api-server在本地暴露的127.0.0.1:8080交互
备注： 未实现HA模式 ，实现HA模式，官方的文档https://kubernetes.io/docs/admin/high-availability/里指明：需要etcd实现集群模式，apiserver是无状态的，在master节点上正常启动，利用云上的lb做负载均衡，感觉dns也行，注意证书问题就可以。，kube-controller-manager，kube-scheduler需要保证同时只有一个实例在work启动加上--leader-elect启动参数。
 etcd组件说明： port: 127.0.0.1:2379: listen-client 127.0.0.1:2380: initial-cluster  kubelet组件说明： port: 4194: cadvisor-port #cadvisor作为kubernetes一个组件集成在kubelet里 127.0.0.1:10248: localhost healthz endpoint # 10250: Kubelet to server on listen for HTTP and respond to a simple API (underspec’d currently) to submit a new manifest. 10255: The read-only port for the Kubelet to serve on with no authentication/authorization # 只读暴露kubelet里的指标 http://192.168.199.142:10255/stats/summary  kube-proxy组件： port： 127.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://blog.zhoulouzi.com/2017/11/raft/">
                <h3 class="media-heading">Raft 初识</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">the secret lives of data http://thesecretlivesofdata.com/raft/
the Raft Consensus Algorithm https://raft.github.io/
Raft: The raft-the-understandable-distributed-consensus-protocol Distributed Consensus Protocol https://speakerdeck.com/benbjohnson/raft-the-understandable-distributed-consensus-protocol/</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://blog.zhoulouzi.com/2017/10/minikube/">
                <h3 class="media-heading">minikube install offline</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"> minikube install offline step by step 目标： 在没有网络接入的情况下安装minikube。供公司app demo 演示使用环境,建议在网络正常的情况下使用一次minikube，然后在尝试offline的安装。
准备 需要提前下载几个东西：
 kubectl 的二进制文件 官网下载 放到/usr/local/bin/ 下即可 minikube 的二进制文件 官网下载放到/usr/local/bin/ 下即可 docker的离线安装包 docker 离线安装 minikube要跑起来所需要的docker镜像：
gcr.io/google_containers/kubernetes-dashboard-amd64 v1.6.3 gcr.io/google_containers/k8s-dns-sidecar-amd64 1.14.5 gcr.io/google_containers/k8s-dns-kube-dns-amd64 1.14.5 gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64 1.14.5 gcr.io/google-containers/kube-addon-manager v6.4-beta.2 gcr.io/google_containers/pause-amd64 3.0 docker image save 导出tar包，方便随时在离线环境使用  minikue.iso 下载地址：minikube.iso
  使用定制参数启动minikube /usr/local/bin/minikube start --vm-driver=none --iso-url file://tmp/minikube-v0.23.5.iso --kubernetes-version v1.7.5 --extra-config=apiserver.Service.NodePortRange=0-60000  完成 </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://blog.zhoulouzi.com/2017/09/leetcode/">
                <h3 class="media-heading">leetcode 笔记</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">总结出一些比较意义的题  好久没有更新自己的博客了，自从3月份跳槽到现在这几个月一直很忙，所以也一直没有时间更新，最近自己也抽空去leetcode刷题，补一补薄弱的环节。就从easy难度的开始刷起，刷完这600多道题。
 1. Given an array of integers, every element appears twice except for one. Find that single one. Note: Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory?
 我的解法很平常遍历一遍列表给每个元素计数，返回值为1的元素，但是并不符合Note里提到的。于是在大神们的Solutions找到了这个答案：One-line python solution with O(n) time
 def singleNumber(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; return reduce(lambda x, y: x ^ y, nums)   第一眼看，什么鬼，x 的 y次方～ 想了半天才明白 相同2个数 异或运算结果就是0 0和任意数 异或运算都是 任意数本身啊。 reduce下这个列表，完美。</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://blog.zhoulouzi.com/2017/06/zihuan/">
                <h3 class="media-heading">资环十年</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"> 怀念不如相见。 从去年底，微信群里就滴滴不停，大家怂恿着要回学校给今年毕业的兄弟办一场告别赛。话说我们这帮兄弟都是毕业好几年的人了，整天混迹于校园群聊，还整天BB着那个学院今年来比较有实力的选手，那个学院今年怎么招摇了，押注那个学院今年夺冠，其实我看出来了，都是想回去踢个球，喝顿酒，在学弟面前吹吹逼，找找当年的感觉。
不过说真的，那些年在球队的日子真的是神仙般的生活，踢球，喝酒，吹逼。纯爷们才能一起干的事，你说对吧，Tango？ 5月份，我开始筹备这些事，特别感谢宋忠贤同学的跑腿，帮安排酒店，看欧冠的地方，很不错，大家玩的很嗨。有的兄弟结婚了，有的兄弟事业忙，所以定了一个6月3，4日一个不太炎热的日子。最后报名人数还可以20个人，最后各种原因你懂的，实际到场人数大打折扣。毕了业还这么坑？田老板？毅哥？这二位都是毕业好久没见的兄弟，挺想你们的，上次在北京，没喝够。 老五，谁在我上铺的兄弟，4年的感情一碰就会哭。胖了，听说偷偷跑回学校表白小学妹了？可以啊，66666。 继红哥，球技又提升了，有空回太原和你和亮哥踢，当年教诲，培养毕生难忘。 晓龙，敢无视老子太上皇的位子，成天在学弟面前贬低我的17号？对象不错。嗯。 胖子，你不来，你后悔不，见不了你哥。
附靓照N张：
2017年6月3日: 与学弟们的合照 2010年校联赛-资源环境学院冠军 2011年校联赛-资源环境学院八强 2012年校联赛-资源环境学院八强 2013年校联赛-资源环境学院亚军 </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://blog.zhoulouzi.com/2017/03/docker/">
                <h3 class="media-heading">docker pre-install kernel-check</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">docker pre-install kernel-check Docker官方明确要求了kernel版本要在version 3.10及以上，（但是在centos上还是遇到了很多bug，如果你用centos7我觉得应该在3.18以上，ubuntu的内核比较新，出问题较少）另外官方还是提供了一个check脚本，所以我们可以利用这个脚本check下我们的kernel缺少那些东西。
step 1、curl https://raw.githubusercontent.com/docker/docker/master/contrib/check-config.sh &gt; check-config.sh 2、bash ./check-config.sh  result [root@master1 ~]# bash check-config.sh warning: /proc/config.gz does not exist, searching other paths for kernel config ... info: reading kernel config from /boot/config-3.10.0-693.el7.x86_64 ... Generally Necessary: - cgroup hierarchy: properly mounted [/sys/fs/cgroup] - CONFIG_NAMESPACES: enabled - CONFIG_NET_NS: enabled - CONFIG_PID_NS: enabled - CONFIG_IPC_NS: enabled - CONFIG_UTS_NS: enabled - CONFIG_CGROUPS: enabled - CONFIG_CGROUP_CPUACCT: enabled - CONFIG_CGROUP_DEVICE: enabled - CONFIG_CGROUP_FREEZER: enabled - CONFIG_CGROUP_SCHED: enabled - CONFIG_CPUSETS: enabled - CONFIG_MEMCG: enabled - CONFIG_KEYS: enabled - CONFIG_VETH: enabled (as module) - CONFIG_BRIDGE: enabled (as module) - CONFIG_BRIDGE_NETFILTER: enabled (as module) - CONFIG_NF_NAT_IPV4: enabled (as module) - CONFIG_IP_NF_FILTER: enabled (as module) - CONFIG_IP_NF_TARGET_MASQUERADE: enabled (as module) - CONFIG_NETFILTER_XT_MATCH_ADDRTYPE: enabled (as module) - CONFIG_NETFILTER_XT_MATCH_CONNTRACK: enabled (as module) - CONFIG_NETFILTER_XT_MATCH_IPVS: enabled (as module) - CONFIG_IP_NF_NAT: enabled (as module) - CONFIG_NF_NAT: enabled (as module) - CONFIG_NF_NAT_NEEDED: enabled - CONFIG_POSIX_MQUEUE: enabled - CONFIG_DEVPTS_MULTIPLE_INSTANCES: enabled Optional Features: - CONFIG_USER_NS: enabled (RHEL7/CentOS7: User namespaces disabled; add 'user_namespace.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         9 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('https://res.cloudinary.com/ddvxfzzbe/image/upload/v1513355392/ChMkJ1f8ljWIBAmcAA-gWT6p-0oAAWzegGSHVwAD6Bx012_telyks.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="https://blog.zhoulouzi.com/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>




  
    
      <script>
        var disqus_config = function () {
          this.page.url = 'https:\/\/blog.zhoulouzi.com\/2017\/11\/kubernetes\/';
          
            this.page.identifier = '\/2017\/11\/kubernetes\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'blog-zhoulouzi-com';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

